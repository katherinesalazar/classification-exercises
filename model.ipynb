{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from acquire import get_titanic_data\n",
    "\n",
    "from prepare_cu import prep_titanic\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the data\n",
    "df = get_titanic_data()\n",
    "\n",
    "# prepare the data\n",
    "train, validate, test = prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex        age  sibsp  parch  \\\n",
       "583           583         0       1    male  36.000000      0      0   \n",
       "337           337         1       1  female  41.000000      0      0   \n",
       "50             50         0       3    male   7.000000      4      1   \n",
       "218           218         1       1  female  32.000000      0      0   \n",
       "31             31         1       1  female  29.916875      1      0   \n",
       "\n",
       "         fare embarked  class  embark_town  alone  Q  S  \n",
       "583   40.1250        C  First    Cherbourg      1  0  0  \n",
       "337  134.5000        C  First    Cherbourg      1  0  0  \n",
       "50    39.6875        S  Third  Southampton      0  0  1  \n",
       "218   76.2917        C  First    Cherbourg      1  0  0  \n",
       "31   146.5208        C  First    Cherbourg      0  0  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop out non-numerical columns or non-encoded version remaining in this data set\n",
    "drops = ['sex', 'class','embarked', 'embark_town', 'passenger_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dataset.drop(columns=drops, inplace=True) for dataset in [train, validate, test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  Q  S\n",
       "583         0       1  36.000000      0      0   40.1250      1  0  0\n",
       "337         1       1  41.000000      0      0  134.5000      1  0  0\n",
       "50          0       3   7.000000      4      1   39.6875      0  0  1\n",
       "218         1       1  32.000000      0      0   76.2917      1  0  0\n",
       "31          1       1  29.916875      1      0  146.5208      0  0  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier Model will predict survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Exercises\n",
    " - https://ds.codeup.com/classification/decision-trees/#installing-graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is your baseline prediction? What is your baseline accuracy?\n",
    "- Baseline prediction is 62% accuracy when always predicting death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    190\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain our mode\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline is death = 0 as there are 307 deaths (mode) and only 190 suvivors\n",
    "train['baseline_death'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>baseline_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  Q  S  \\\n",
       "583         0       1  36.000000      0      0   40.1250      1  0  0   \n",
       "337         1       1  41.000000      0      0  134.5000      1  0  0   \n",
       "50          0       3   7.000000      4      1   39.6875      0  0  1   \n",
       "218         1       1  32.000000      0      0   76.2917      1  0  0   \n",
       "31          1       1  29.916875      1      0  146.5208      0  0  0   \n",
       "\n",
       "     baseline_death  \n",
       "583               0  \n",
       "337               0  \n",
       "50                0  \n",
       "218               0  \n",
       "31                0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline accuracy for nonsurvival in all cases on the Titanic Dataset is 0.618\n"
     ]
    }
   ],
   "source": [
    "print(f'Our baseline accuracy for nonsurvival in all cases on the Titanic Dataset is {(train.baseline_death == train.survived).mean():.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       307\n",
      "           1       1.00      0.00      0.00       190\n",
      "\n",
      "    accuracy                           0.62       497\n",
      "   macro avg       0.81      0.50      0.38       497\n",
      "weighted avg       0.76      0.62      0.47       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_class_report = classification_report(train.survived, train.baseline_death, zero_division=True)\n",
    "print(baseline_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove baseline assumption from the train\n",
    "train.drop(columns='baseline_death', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split our X and y\n",
    "X_train = train.drop(columns='survived')\n",
    "y_train = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# designate our X and y\n",
    "X = X_train\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy for our model is 0.9738\n",
      "The True Positive Rate is 0.968, The False Positive Rate is 0.0228,\n",
      "The True Negative Rate is 0.977, and the False Negative Rate is 0.0316\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.977199</td>\n",
       "      <td>0.978793</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963351</td>\n",
       "      <td>0.968421</td>\n",
       "      <td>0.965879</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.971871</td>\n",
       "      <td>0.972810</td>\n",
       "      <td>0.972336</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.973877</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973856</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.980392  0.977199  0.978793  307.000000\n",
       "1              0.963351  0.968421  0.965879  190.000000\n",
       "accuracy       0.973843  0.973843  0.973843    0.973843\n",
       "macro avg      0.971871  0.972810  0.972336  497.000000\n",
       "weighted avg   0.973877  0.973843  0.973856  497.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = dtc.score(X, y)\n",
    "y_pred = dtc.predict(X)\n",
    "conf = confusion_matrix(y, y_pred)\n",
    "#class report\n",
    "class_report = pd.DataFrame(classification_report(y, y_pred, output_dict=True)).T\n",
    "conf = confusion_matrix(y, y_pred)\n",
    "#true positive rate\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "#false positvive rate\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "#true negative rate\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "#false negative rate\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "\n",
    "print(f'''\n",
    "The accuracy for our model is {accuracy:.4}\n",
    "The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "''')\n",
    "class_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to predict\n",
    "#dtc\n",
    "y_pred = dtc.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    306\n",
       "1    191\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the values in the predictions\n",
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model score: accuracy\n",
    "accuracy = dtc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9738430583501007"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "conf = confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[300,   7],\n",
       "       [  6, 184]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the classification report\n",
    "class_report = classification_report(y_train, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9803921568627451,\n",
       "  'recall': 0.9771986970684039,\n",
       "  'f1-score': 0.9787928221859705,\n",
       "  'support': 307},\n",
       " '1': {'precision': 0.9633507853403142,\n",
       "  'recall': 0.968421052631579,\n",
       "  'f1-score': 0.9658792650918635,\n",
       "  'support': 190},\n",
       " 'accuracy': 0.9738430583501007,\n",
       " 'macro avg': {'precision': 0.9718714711015296,\n",
       "  'recall': 0.9728098748499914,\n",
       "  'f1-score': 0.972336043638917,\n",
       "  'support': 497},\n",
       " 'weighted avg': {'precision': 0.9738773468239887,\n",
       "  'recall': 0.9738430583501007,\n",
       "  'f1-score': 0.9738560498562314,\n",
       "  'support': 497}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deceased</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.977199</td>\n",
       "      <td>0.978793</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.963351</td>\n",
       "      <td>0.968421</td>\n",
       "      <td>0.965879</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.971871</td>\n",
       "      <td>0.972810</td>\n",
       "      <td>0.972336</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.973877</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973856</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "deceased       0.980392  0.977199  0.978793  307.000000\n",
       "survived       0.963351  0.968421  0.965879  190.000000\n",
       "accuracy       0.973843  0.973843  0.973843    0.973843\n",
       "macro avg      0.971871  0.972810  0.972336  497.000000\n",
       "weighted avg   0.973877  0.973843  0.973856  497.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(class_report).rename(columns={'0': 'deceased', '1': 'survived'}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[300,   7],\n",
       "       [  6, 184]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn our confusio matrix into a dataframe for uman legibility:\n",
    "conf_df = pd.DataFrame(conf, columns=['predict death', 'predict_survive'], index=['actual_death', 'actual_survive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>300</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>6</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predict death  predict_survive\n",
       "actual_death              300                7\n",
       "actual_survive              6              184"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a key for reference\n",
    "rubric_df = pd.DataFrame([['true negative', 'false positive'],['false negative', 'true positive']], columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>true negative</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>false negative</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predict_death predict_survive\n",
       "actual_death     true negative  false positive\n",
       "actual_survive  false negative   true positive"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.concat([conf_df, rubric_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>true negative:300</td>\n",
       "      <td>false positive:7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>false negative:6</td>\n",
       "      <td>true positive:184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    predict_death    predict_survive\n",
       "actual_death    true negative:300   false positive:7\n",
       "actual_survive   false negative:6  true positive:184"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubric_df + ':'+ conf_df.values.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run through steps 2-4 using a different max_depth value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtc2\n",
    "dtc2 = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtc2.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy for our model is 0.9738\n",
      "The True Positive Rate is 0.968, The False Positive Rate is 0.0228,\n",
      "The True Negative Rate is 0.977, and the False Negative Rate is 0.0316\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.977199</td>\n",
       "      <td>0.978793</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963351</td>\n",
       "      <td>0.968421</td>\n",
       "      <td>0.965879</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.971871</td>\n",
       "      <td>0.972810</td>\n",
       "      <td>0.972336</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.973877</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.973856</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.980392  0.977199  0.978793  307.000000\n",
       "1              0.963351  0.968421  0.965879  190.000000\n",
       "accuracy       0.973843  0.973843  0.973843    0.973843\n",
       "macro avg      0.971871  0.972810  0.972336  497.000000\n",
       "weighted avg   0.973877  0.973843  0.973856  497.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model #1:\n",
    "accuracy = dtc.score(X, y)\n",
    "y_pred = dtc.predict(X)\n",
    "conf = confusion_matrix(y, y_pred)\n",
    "class_report = pd.DataFrame(classification_report(y, y_pred, output_dict=True)).T\n",
    "conf = confusion_matrix(y, y_pred)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "The accuracy for our model is {accuracy:.4}\n",
    "The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "''')\n",
    "class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy for our model is 0.7123\n",
      "The True Positive Rate is 0.342, The False Positive Rate is 0.0586,\n",
      "The True Negative Rate is 0.941, and the False Negative Rate is 0.658\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.698068</td>\n",
       "      <td>0.941368</td>\n",
       "      <td>0.801664</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.712274</td>\n",
       "      <td>0.712274</td>\n",
       "      <td>0.712274</td>\n",
       "      <td>0.712274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.740600</td>\n",
       "      <td>0.641737</td>\n",
       "      <td>0.638927</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.730587</td>\n",
       "      <td>0.712274</td>\n",
       "      <td>0.677238</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.698068  0.941368  0.801664  307.000000\n",
       "1              0.783133  0.342105  0.476190  190.000000\n",
       "accuracy       0.712274  0.712274  0.712274    0.712274\n",
       "macro avg      0.740600  0.641737  0.638927  497.000000\n",
       "weighted avg   0.730587  0.712274  0.677238  497.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Model #2:\n",
    "accuracy = dtc2.score(X, y)\n",
    "y_pred = dtc2.predict(X)\n",
    "conf = confusion_matrix(y, y_pred)\n",
    "class_report = pd.DataFrame(classification_report(y, y_pred, output_dict=True)).T\n",
    "conf = confusion_matrix(y, y_pred)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "The accuracy for our model is {accuracy:.4}\n",
    "The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "''')\n",
    "class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for our validation sets\n",
    "y_val_pred_1 = dtc.predict(validate.drop(columns='survived'))\n",
    "y_val_pred_2 = dtc2.predict(validate.drop(columns='survived'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get validation accuracy\n",
    "accuracy_v_1 = dtc.score(validate.drop(columns='survived'), validate.survived)\n",
    "accuracy_v_2 = dtc2.score(validate.drop(columns='survived'), validate.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6588785046728972"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model 1\n",
    "accuracy_v_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7102803738317757"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model 2\n",
    "accuracy_v_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dot_data = export_graphviz(dtc2, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_model_2_tree.pdf'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.render('titanic_model_2_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dot_data = export_graphviz(dtc, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_model_1_tree.pdf'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.render('titanic_model_1_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Exercises\n",
    "    - https://ds.codeup.com/classification/random-forests/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from acquire_cu import get_titanic_data\n",
    "from prepare_cu import prep_titanic\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire the data\n",
    "df = get_titanic_data()\n",
    "#prepare the data\n",
    "train, validate, test = prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex        age  sibsp  parch  \\\n",
       "583           583         0       1    male  36.000000      0      0   \n",
       "337           337         1       1  female  41.000000      0      0   \n",
       "50             50         0       3    male   7.000000      4      1   \n",
       "218           218         1       1  female  32.000000      0      0   \n",
       "31             31         1       1  female  29.916875      1      0   \n",
       "\n",
       "         fare embarked  class  embark_town  alone  Q  S  \n",
       "583   40.1250        C  First    Cherbourg      1  0  0  \n",
       "337  134.5000        C  First    Cherbourg      1  0  0  \n",
       "50    39.6875        S  Third  Southampton      0  0  1  \n",
       "218   76.2917        C  First    Cherbourg      1  0  0  \n",
       "31   146.5208        C  First    Cherbourg      0  0  0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any non-numerical columns in the data set\n",
    "drops = ['sex', 'class', 'embarked', 'embark_town', 'passenger_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [train, validate, test]: \n",
    "    dataset.drop(columns=drops, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  Q  S\n",
       "583         0       1  36.000000      0      0   40.1250      1  0  0\n",
       "337         1       1  41.000000      0      0  134.5000      1  0  0\n",
       "50          0       3   7.000000      4      1   39.6875      0  0  1\n",
       "218         1       1  32.000000      0      0   76.2917      1  0  0\n",
       "31          1       1  29.916875      1      0  146.5208      0  0  0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived    0.617706\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create baseline is at 62 %\n",
    "baseline = (y_train.value_counts().idxmax() == y_train).mean()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forrest Model\n",
    "\n",
    "clf = RandomForestClassifier(min_samples_leaf = 1, max_depth = 10, random_state = 1349)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model after splitting our X and y\n",
    "X_train, y_train = train.drop(columns='survived'), train.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=1349)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the thing\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the thing\n",
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.9276\n",
      "    The True Positive Rate is 0.868, The False Positive Rate is 0.0358,\n",
      "    The True Negative Rate is 0.964, and the False Negative Rate is 0.132\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.922118</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.929809</td>\n",
       "      <td>0.927999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.964169</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.916295</td>\n",
       "      <td>0.927565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.922157</td>\n",
       "      <td>0.926987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.922118    0.937500  0.927565    0.929809      0.927999\n",
       "recall       0.964169    0.868421  0.927565    0.916295      0.927565\n",
       "f1-score     0.942675    0.901639  0.927565    0.922157      0.926987\n",
       "support    307.000000  190.000000  0.927565  497.000000    497.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_score = clf.score(X_train, y_train)\n",
    "conf = confusion_matrix(y_train, y_pred)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "    The accuracy for our model is {clf_score:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest Model\n",
    "\n",
    "clf1 = RandomForestClassifier(min_samples_leaf=3, max_depth=3, random_state=1349)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, min_samples_leaf=3, random_state=1349)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.7525\n",
      "    The True Positive Rate is 0.537, The False Positive Rate is 0.114,\n",
      "    The True Negative Rate is 0.886, and the False Negative Rate is 0.463\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.922118</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.929809</td>\n",
       "      <td>0.927999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.964169</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.916295</td>\n",
       "      <td>0.927565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.922157</td>\n",
       "      <td>0.926987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.922118    0.937500  0.927565    0.929809      0.927999\n",
       "recall       0.964169    0.868421  0.927565    0.916295      0.927565\n",
       "f1-score     0.942675    0.901639  0.927565    0.922157      0.926987\n",
       "support    307.000000  190.000000  0.927565  497.000000    497.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = clf1.predict(X_train)\n",
    "clf_score = clf1.score(X_train, y_train)\n",
    "conf = confusion_matrix(y_train, y_pred1)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "    The accuracy for our model is {clf_score:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = validate.drop(columns='survived'), validate.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1: min samples 1, max depth 10: ON VALIDATE SET\n",
      "\n",
      "    The accuracy for our model is 0.7617\n",
      "    The True Positive Rate is 0.646, The False Positive Rate is 0.167,\n",
      "    The True Negative Rate is 0.833, and the False Negative Rate is 0.354\n",
      "    \n",
      "-------------------------------------------\n",
      " Model #2: min samples 3, max_depth 3 : ON VALIDATE SET\n",
      "\n",
      "\n",
      "    The accuracy for our model is 0.743\n",
      "    The True Positive Rate is 0.5, The False Positive Rate is 0.106,\n",
      "    The True Negative Rate is 0.894, and the False Negative Rate is 0.5\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print('Model #1: min samples 1, max depth 10: ON VALIDATE SET')\n",
    "clf_score = clf.score(X_val, y_val)\n",
    "y_pred_val = clf.predict(X_val)\n",
    "conf = confusion_matrix(y_val, y_pred_val)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "    The accuracy for our model is {clf_score:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "print('-------------------------------------------\\n Model #2: min samples 3, max_depth 3 : ON VALIDATE SET\\n')\n",
    "clf_score = clf1.score(X_val, y_val)\n",
    "y_pred_val1 = clf1.predict(X_val)\n",
    "conf = confusion_matrix(y_val, y_pred_val1)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "    The accuracy for our model is {clf_score:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[296,  11],\n",
       "       [ 25, 165]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key for reference\n",
    "rubric_df = pd.DataFrame([['true negative', 'false positive'],['false negative', 'true positive']], columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>true negative</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>false negative</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predict_death predict_survive\n",
       "actual_death     true negative  false positive\n",
       "actual_survive  false negative   true positive"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70104785, 0.29895215],\n",
       "       [0.06711869, 0.93288131],\n",
       "       [0.9758    , 0.0242    ],\n",
       "       [0.10064358, 0.89935642],\n",
       "       [0.0443181 , 0.9556819 ],\n",
       "       [0.68404055, 0.31595945],\n",
       "       [0.47006918, 0.52993082],\n",
       "       [0.67405366, 0.32594634],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [1.        , 0.        ],\n",
       "       [0.82134381, 0.17865619],\n",
       "       [0.89806093, 0.10193907],\n",
       "       [0.13108025, 0.86891975],\n",
       "       [0.59453012, 0.40546988],\n",
       "       [0.60759589, 0.39240411],\n",
       "       [0.38816308, 0.61183692],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.18171429, 0.81828571],\n",
       "       [0.5230589 , 0.4769411 ],\n",
       "       [0.78048702, 0.21951298],\n",
       "       [0.13383776, 0.86616224],\n",
       "       [0.82246706, 0.17753294],\n",
       "       [0.2079232 , 0.7920768 ],\n",
       "       [0.19833333, 0.80166667],\n",
       "       [0.38900423, 0.61099577],\n",
       "       [0.93237155, 0.06762845],\n",
       "       [0.12313969, 0.87686031],\n",
       "       [0.77758204, 0.22241796],\n",
       "       [0.58227628, 0.41772372],\n",
       "       [0.67053517, 0.32946483],\n",
       "       [0.85851765, 0.14148235],\n",
       "       [0.75484745, 0.24515255],\n",
       "       [0.92370488, 0.07629512],\n",
       "       [0.04768984, 0.95231016],\n",
       "       [0.22601563, 0.77398437],\n",
       "       [0.18027778, 0.81972222],\n",
       "       [0.74415807, 0.25584193],\n",
       "       [0.0596152 , 0.9403848 ],\n",
       "       [0.79486773, 0.20513227],\n",
       "       [0.73784029, 0.26215971],\n",
       "       [0.86005014, 0.13994986],\n",
       "       [0.81075661, 0.18924339],\n",
       "       [0.90496667, 0.09503333],\n",
       "       [0.37851492, 0.62148508],\n",
       "       [0.5731157 , 0.4268843 ],\n",
       "       [0.93241277, 0.06758723],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.90088236, 0.09911764],\n",
       "       [0.5731029 , 0.4268971 ],\n",
       "       [0.7666286 , 0.2333714 ],\n",
       "       [0.91547289, 0.08452711],\n",
       "       [0.84069255, 0.15930745],\n",
       "       [0.16117767, 0.83882233],\n",
       "       [0.05594747, 0.94405253],\n",
       "       [0.59250786, 0.40749214],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.83666942, 0.16333058],\n",
       "       [0.17482381, 0.82517619],\n",
       "       [0.34008241, 0.65991759],\n",
       "       [0.92063425, 0.07936575],\n",
       "       [0.70071813, 0.29928187],\n",
       "       [0.9378264 , 0.0621736 ],\n",
       "       [0.98718893, 0.01281107],\n",
       "       [0.63788704, 0.36211296],\n",
       "       [0.73349848, 0.26650152],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.08295586, 0.91704414],\n",
       "       [0.97817787, 0.02182213],\n",
       "       [0.17611851, 0.82388149],\n",
       "       [0.07955   , 0.92045   ],\n",
       "       [0.94      , 0.06      ],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.14183408, 0.85816592],\n",
       "       [0.23233633, 0.76766367],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.82846273, 0.17153727],\n",
       "       [0.88996544, 0.11003456],\n",
       "       [0.88497769, 0.11502231],\n",
       "       [0.85356935, 0.14643065],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.55264654, 0.44735346],\n",
       "       [0.01562189, 0.98437811],\n",
       "       [0.9814894 , 0.0185106 ],\n",
       "       [0.59250786, 0.40749214],\n",
       "       [0.90834427, 0.09165573],\n",
       "       [0.69828571, 0.30171429],\n",
       "       [0.55339281, 0.44660719],\n",
       "       [0.08962624, 0.91037376],\n",
       "       [0.05516855, 0.94483145],\n",
       "       [0.88497769, 0.11502231],\n",
       "       [0.9507045 , 0.0492955 ],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.23229147, 0.76770853],\n",
       "       [0.05853477, 0.94146523],\n",
       "       [0.62384949, 0.37615051],\n",
       "       [0.92561734, 0.07438266],\n",
       "       [0.18691687, 0.81308313],\n",
       "       [0.81784127, 0.18215873],\n",
       "       [0.82209022, 0.17790978],\n",
       "       [0.57422022, 0.42577978],\n",
       "       [0.9076779 , 0.0923221 ],\n",
       "       [0.73552381, 0.26447619],\n",
       "       [0.24772643, 0.75227357],\n",
       "       [0.92075841, 0.07924159],\n",
       "       [0.62229437, 0.37770563],\n",
       "       [0.09444455, 0.90555545],\n",
       "       [0.87077778, 0.12922222],\n",
       "       [0.08586666, 0.91413334],\n",
       "       [0.93498531, 0.06501469],\n",
       "       [0.92047293, 0.07952707],\n",
       "       [0.11232749, 0.88767251],\n",
       "       [0.12612082, 0.87387918],\n",
       "       [0.78427497, 0.21572503],\n",
       "       [0.87136462, 0.12863538],\n",
       "       [0.93579263, 0.06420737],\n",
       "       [0.17899516, 0.82100484],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85130215, 0.14869785],\n",
       "       [0.08194455, 0.91805545],\n",
       "       [0.17710255, 0.82289745],\n",
       "       [0.83302659, 0.16697341],\n",
       "       [0.98857143, 0.01142857],\n",
       "       [0.45745595, 0.54254405],\n",
       "       [0.90769791, 0.09230209],\n",
       "       [0.44776311, 0.55223689],\n",
       "       [0.48610091, 0.51389909],\n",
       "       [0.5230589 , 0.4769411 ],\n",
       "       [0.66000158, 0.33999842],\n",
       "       [0.48255263, 0.51744737],\n",
       "       [0.9358    , 0.0642    ],\n",
       "       [0.06407323, 0.93592677],\n",
       "       [0.89978306, 0.10021694],\n",
       "       [0.9808    , 0.0192    ],\n",
       "       [0.3192716 , 0.6807284 ],\n",
       "       [0.66505911, 0.33494089],\n",
       "       [0.88202362, 0.11797638],\n",
       "       [0.89716117, 0.10283883],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.52714657, 0.47285343],\n",
       "       [0.66445971, 0.33554029],\n",
       "       [0.34893111, 0.65106889],\n",
       "       [0.5968727 , 0.4031273 ],\n",
       "       [0.72762096, 0.27237904],\n",
       "       [0.88293763, 0.11706237],\n",
       "       [0.7845821 , 0.2154179 ],\n",
       "       [0.16068023, 0.83931977],\n",
       "       [0.217675  , 0.782325  ],\n",
       "       [0.51473801, 0.48526199],\n",
       "       [0.09414863, 0.90585137],\n",
       "       [0.4328094 , 0.5671906 ],\n",
       "       [0.9378264 , 0.0621736 ],\n",
       "       [0.37540969, 0.62459031],\n",
       "       [0.1397112 , 0.8602888 ],\n",
       "       [0.94167187, 0.05832813],\n",
       "       [0.75353488, 0.24646512],\n",
       "       [0.25075372, 0.74924628],\n",
       "       [0.95738845, 0.04261155],\n",
       "       [0.94167187, 0.05832813],\n",
       "       [0.38900423, 0.61099577],\n",
       "       [0.96150371, 0.03849629],\n",
       "       [0.88084127, 0.11915873],\n",
       "       [0.36633433, 0.63366567],\n",
       "       [0.72333117, 0.27666883],\n",
       "       [0.51597755, 0.48402245],\n",
       "       [0.93083705, 0.06916295],\n",
       "       [0.98016291, 0.01983709],\n",
       "       [0.98      , 0.02      ],\n",
       "       [0.81130215, 0.18869785],\n",
       "       [0.75629929, 0.24370071],\n",
       "       [0.9814894 , 0.0185106 ],\n",
       "       [0.76486901, 0.23513099],\n",
       "       [0.0690814 , 0.9309186 ],\n",
       "       [0.13113768, 0.86886232],\n",
       "       [0.8510878 , 0.1489122 ],\n",
       "       [0.81907075, 0.18092925],\n",
       "       [0.87914557, 0.12085443],\n",
       "       [0.75741964, 0.24258036],\n",
       "       [0.9935246 , 0.0064754 ],\n",
       "       [0.97498246, 0.02501754],\n",
       "       [0.61889703, 0.38110297],\n",
       "       [0.92533426, 0.07466574],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.91715647, 0.08284353],\n",
       "       [0.4417864 , 0.5582136 ],\n",
       "       [0.92047293, 0.07952707],\n",
       "       [0.7787234 , 0.2212766 ],\n",
       "       [0.81601526, 0.18398474],\n",
       "       [0.10035952, 0.89964048],\n",
       "       [0.89692308, 0.10307692],\n",
       "       [0.63237491, 0.36762509],\n",
       "       [0.75730758, 0.24269242],\n",
       "       [0.07090959, 0.92909041],\n",
       "       [0.94120771, 0.05879229],\n",
       "       [0.89053325, 0.10946675],\n",
       "       [0.02482778, 0.97517222],\n",
       "       [0.01316111, 0.98683889],\n",
       "       [0.73405217, 0.26594783],\n",
       "       [0.27488624, 0.72511376],\n",
       "       [0.90601504, 0.09398496],\n",
       "       [0.91662937, 0.08337063],\n",
       "       [1.        , 0.        ],\n",
       "       [0.2833677 , 0.7166323 ],\n",
       "       [0.05338055, 0.94661945],\n",
       "       [0.92555538, 0.07444462],\n",
       "       [0.79905518, 0.20094482],\n",
       "       [0.9814894 , 0.0185106 ],\n",
       "       [0.80328602, 0.19671398],\n",
       "       [0.61784644, 0.38215356],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.38895184, 0.61104816],\n",
       "       [0.87870632, 0.12129368],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.70705721, 0.29294279],\n",
       "       [0.56743186, 0.43256814],\n",
       "       [0.23939524, 0.76060476],\n",
       "       [0.11685076, 0.88314924],\n",
       "       [0.91169879, 0.08830121],\n",
       "       [0.88293763, 0.11706237],\n",
       "       [0.29632334, 0.70367666],\n",
       "       [0.98259679, 0.01740321],\n",
       "       [0.54540655, 0.45459345],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.82072969, 0.17927031],\n",
       "       [0.30041715, 0.69958285],\n",
       "       [0.99857143, 0.00142857],\n",
       "       [0.9507045 , 0.0492955 ],\n",
       "       [0.54725408, 0.45274592],\n",
       "       [0.31731815, 0.68268185],\n",
       "       [0.90438994, 0.09561006],\n",
       "       [0.26002441, 0.73997559],\n",
       "       [0.62857944, 0.37142056],\n",
       "       [0.88003061, 0.11996939],\n",
       "       [0.92047293, 0.07952707],\n",
       "       [0.84716342, 0.15283658],\n",
       "       [0.91662937, 0.08337063],\n",
       "       [0.26687433, 0.73312567],\n",
       "       [0.265     , 0.735     ],\n",
       "       [0.98718893, 0.01281107],\n",
       "       [0.88382842, 0.11617158],\n",
       "       [0.97746667, 0.02253333],\n",
       "       [0.94120771, 0.05879229],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.11741028, 0.88258972],\n",
       "       [0.17667717, 0.82332283],\n",
       "       [0.02062189, 0.97937811],\n",
       "       [0.98857143, 0.01142857],\n",
       "       [0.06407323, 0.93592677],\n",
       "       [0.96220092, 0.03779908],\n",
       "       [0.2254543 , 0.7745457 ],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.80188818, 0.19811182],\n",
       "       [0.5180364 , 0.4819636 ],\n",
       "       [0.92378443, 0.07621557],\n",
       "       [0.3325494 , 0.6674506 ],\n",
       "       [0.70717819, 0.29282181],\n",
       "       [0.33181818, 0.66818182],\n",
       "       [0.94959875, 0.05040125],\n",
       "       [0.07197777, 0.92802223],\n",
       "       [0.10939258, 0.89060742],\n",
       "       [0.40738353, 0.59261647],\n",
       "       [0.53187622, 0.46812378],\n",
       "       [0.87577115, 0.12422885],\n",
       "       [0.22395145, 0.77604855],\n",
       "       [0.63011331, 0.36988669],\n",
       "       [0.9814894 , 0.0185106 ],\n",
       "       [0.87082968, 0.12917032],\n",
       "       [0.96416667, 0.03583333],\n",
       "       [0.33212895, 0.66787105],\n",
       "       [0.93498531, 0.06501469],\n",
       "       [0.85190868, 0.14809132],\n",
       "       [0.86302395, 0.13697605],\n",
       "       [0.70692399, 0.29307601],\n",
       "       [0.96470405, 0.03529595],\n",
       "       [0.49127534, 0.50872466],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95651534, 0.04348466],\n",
       "       [0.84119107, 0.15880893],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.92925282, 0.07074718],\n",
       "       [0.92925282, 0.07074718],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.69318588, 0.30681412],\n",
       "       [0.51145258, 0.48854742],\n",
       "       [0.8457094 , 0.1542906 ],\n",
       "       [0.85846304, 0.14153696],\n",
       "       [0.16907323, 0.83092677],\n",
       "       [0.53187622, 0.46812378],\n",
       "       [0.70665152, 0.29334848],\n",
       "       [0.77695759, 0.22304241],\n",
       "       [0.86943559, 0.13056441],\n",
       "       [0.80548335, 0.19451665],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.95470405, 0.04529595],\n",
       "       [0.61184565, 0.38815435],\n",
       "       [0.05517808, 0.94482192],\n",
       "       [0.72478512, 0.27521488],\n",
       "       [0.90438994, 0.09561006],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.96558151, 0.03441849],\n",
       "       [0.16176498, 0.83823502],\n",
       "       [0.86005014, 0.13994986],\n",
       "       [0.96750371, 0.03249629],\n",
       "       [0.08356666, 0.91643334],\n",
       "       [0.92378443, 0.07621557],\n",
       "       [0.86806093, 0.13193907],\n",
       "       [0.22714141, 0.77285859],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.80585382, 0.19414618],\n",
       "       [0.65456825, 0.34543175],\n",
       "       [0.89053325, 0.10946675],\n",
       "       [0.85656411, 0.14343589],\n",
       "       [0.929862  , 0.070138  ],\n",
       "       [0.31873585, 0.68126415],\n",
       "       [0.9708    , 0.0292    ],\n",
       "       [0.90494398, 0.09505602],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.0847697 , 0.9152303 ],\n",
       "       [0.14621739, 0.85378261],\n",
       "       [0.99711012, 0.00288988],\n",
       "       [0.95514332, 0.04485668],\n",
       "       [0.88545459, 0.11454541],\n",
       "       [0.42539182, 0.57460818],\n",
       "       [0.71172434, 0.28827566],\n",
       "       [0.83474629, 0.16525371],\n",
       "       [0.46478376, 0.53521624],\n",
       "       [0.30275502, 0.69724498],\n",
       "       [0.3467012 , 0.6532988 ],\n",
       "       [0.13561625, 0.86438375],\n",
       "       [0.10276596, 0.89723404],\n",
       "       [0.95249611, 0.04750389],\n",
       "       [0.5230589 , 0.4769411 ],\n",
       "       [0.16155   , 0.83845   ],\n",
       "       [0.07372013, 0.92627987],\n",
       "       [0.13108025, 0.86891975],\n",
       "       [0.43168132, 0.56831868],\n",
       "       [0.96246667, 0.03753333],\n",
       "       [0.09195758, 0.90804242],\n",
       "       [0.84069255, 0.15930745],\n",
       "       [0.32905365, 0.67094635],\n",
       "       [0.71822338, 0.28177662],\n",
       "       [0.04768984, 0.95231016],\n",
       "       [0.11117098, 0.88882902],\n",
       "       [0.23920481, 0.76079519],\n",
       "       [0.88005276, 0.11994724],\n",
       "       [0.2565246 , 0.7434754 ],\n",
       "       [0.85846304, 0.14153696],\n",
       "       [0.66274864, 0.33725136],\n",
       "       [0.5747074 , 0.4252926 ],\n",
       "       [0.90306093, 0.09693907],\n",
       "       [0.23662333, 0.76337667],\n",
       "       [0.88084127, 0.11915873],\n",
       "       [0.5815418 , 0.4184582 ],\n",
       "       [0.31224799, 0.68775201],\n",
       "       [0.08194455, 0.91805545],\n",
       "       [0.10326172, 0.89673828],\n",
       "       [0.10294179, 0.89705821],\n",
       "       [0.9358    , 0.0642    ],\n",
       "       [0.90494398, 0.09505602],\n",
       "       [0.20618806, 0.79381194],\n",
       "       [0.93849144, 0.06150856],\n",
       "       [0.25165152, 0.74834848],\n",
       "       [0.0468181 , 0.9531819 ],\n",
       "       [0.75256818, 0.24743182],\n",
       "       [0.89992115, 0.10007885],\n",
       "       [0.47637323, 0.52362677],\n",
       "       [0.21274688, 0.78725312],\n",
       "       [0.96484454, 0.03515546],\n",
       "       [0.9858    , 0.0142    ],\n",
       "       [0.48602974, 0.51397026],\n",
       "       [0.89053325, 0.10946675],\n",
       "       [0.77441417, 0.22558583],\n",
       "       [0.82246706, 0.17753294],\n",
       "       [0.71000691, 0.28999309],\n",
       "       [0.26737577, 0.73262423],\n",
       "       [0.91169879, 0.08830121],\n",
       "       [0.09639013, 0.90360987],\n",
       "       [0.68659382, 0.31340618],\n",
       "       [0.1591506 , 0.8408494 ],\n",
       "       [0.36902413, 0.63097587],\n",
       "       [0.29395835, 0.70604165],\n",
       "       [0.42539182, 0.57460818],\n",
       "       [0.26203571, 0.73796429],\n",
       "       [0.9296812 , 0.0703188 ],\n",
       "       [0.62201558, 0.37798442],\n",
       "       [0.27640638, 0.72359362],\n",
       "       [0.98862949, 0.01137051],\n",
       "       [0.46502082, 0.53497918],\n",
       "       [0.68147475, 0.31852525],\n",
       "       [0.81032248, 0.18967752],\n",
       "       [0.9888734 , 0.0111266 ],\n",
       "       [0.05356666, 0.94643334],\n",
       "       [0.62759293, 0.37240707],\n",
       "       [0.89053325, 0.10946675],\n",
       "       [0.25094094, 0.74905906],\n",
       "       [0.84334639, 0.15665361],\n",
       "       [0.42506754, 0.57493246],\n",
       "       [0.98926345, 0.01073655],\n",
       "       [0.88474629, 0.11525371],\n",
       "       [0.83101963, 0.16898037],\n",
       "       [0.89475307, 0.10524693],\n",
       "       [0.10833333, 0.89166667],\n",
       "       [0.75946979, 0.24053021],\n",
       "       [0.55003686, 0.44996314],\n",
       "       [0.65977752, 0.34022248],\n",
       "       [0.50713632, 0.49286368],\n",
       "       [0.63537803, 0.36462197],\n",
       "       [0.83466349, 0.16533651],\n",
       "       [0.90953212, 0.09046788],\n",
       "       [0.76420849, 0.23579151],\n",
       "       [0.90917862, 0.09082138],\n",
       "       [0.97905543, 0.02094457],\n",
       "       [0.7367753 , 0.2632247 ],\n",
       "       [0.93692308, 0.06307692],\n",
       "       [0.13024689, 0.86975311],\n",
       "       [0.20310472, 0.79689528],\n",
       "       [0.0705619 , 0.9294381 ],\n",
       "       [0.92561734, 0.07438266],\n",
       "       [0.09457896, 0.90542104],\n",
       "       [0.67447927, 0.32552073],\n",
       "       [0.23229147, 0.76770853],\n",
       "       [0.94142077, 0.05857923],\n",
       "       [0.9378264 , 0.0621736 ],\n",
       "       [0.49127534, 0.50872466],\n",
       "       [0.49127534, 0.50872466],\n",
       "       [0.12232381, 0.87767619],\n",
       "       [0.86297519, 0.13702481],\n",
       "       [0.19024059, 0.80975941],\n",
       "       [0.8919934 , 0.1080066 ],\n",
       "       [0.5742246 , 0.4257754 ],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.78831401, 0.21168599],\n",
       "       [0.88253128, 0.11746872],\n",
       "       [0.78384745, 0.21615255],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.71409229, 0.28590771],\n",
       "       [0.92075841, 0.07924159],\n",
       "       [0.22912333, 0.77087667],\n",
       "       [0.55339281, 0.44660719],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.95182945, 0.04817055],\n",
       "       [0.91968655, 0.08031345],\n",
       "       [0.53861036, 0.46138964],\n",
       "       [0.93498531, 0.06501469],\n",
       "       [0.31185822, 0.68814178],\n",
       "       [0.97746667, 0.02253333],\n",
       "       [1.        , 0.        ],\n",
       "       [0.10356599, 0.89643401],\n",
       "       [0.96917521, 0.03082479],\n",
       "       [0.31468859, 0.68531141],\n",
       "       [0.28948212, 0.71051788],\n",
       "       [0.96220092, 0.03779908],\n",
       "       [0.71229476, 0.28770524],\n",
       "       [0.11311869, 0.88688131],\n",
       "       [0.21601563, 0.78398437],\n",
       "       [0.95      , 0.05      ],\n",
       "       [0.57744174, 0.42255826],\n",
       "       [0.9686014 , 0.0313986 ],\n",
       "       [0.89053325, 0.10946675],\n",
       "       [0.97356277, 0.02643723],\n",
       "       [0.93367877, 0.06632123],\n",
       "       [0.58198549, 0.41801451],\n",
       "       [0.77105411, 0.22894589],\n",
       "       [0.91126639, 0.08873361],\n",
       "       [0.08084921, 0.91915079],\n",
       "       [0.51702297, 0.48297703],\n",
       "       [0.84949543, 0.15050457],\n",
       "       [0.07295586, 0.92704414],\n",
       "       [0.84039943, 0.15960057],\n",
       "       [0.10195758, 0.89804242],\n",
       "       [0.79404976, 0.20595024],\n",
       "       [0.96558151, 0.03441849],\n",
       "       [0.8638961 , 0.1361039 ],\n",
       "       [0.57688515, 0.42311485],\n",
       "       [0.98862949, 0.01137051],\n",
       "       [0.16356123, 0.83643877],\n",
       "       [0.8958    , 0.1042    ],\n",
       "       [0.66062426, 0.33937574],\n",
       "       [0.85130215, 0.14869785],\n",
       "       [0.16380159, 0.83619841],\n",
       "       [0.56909673, 0.43090327],\n",
       "       [0.26481833, 0.73518167],\n",
       "       [0.17558847, 0.82441153],\n",
       "       [0.9814894 , 0.0185106 ],\n",
       "       [0.05628919, 0.94371081],\n",
       "       [0.07777622, 0.92222378],\n",
       "       [0.05321911, 0.94678089],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.1078181 , 0.8921819 ],\n",
       "       [0.12569643, 0.87430357],\n",
       "       [0.75090234, 0.24909766],\n",
       "       [0.93849144, 0.06150856],\n",
       "       [0.63237491, 0.36762509],\n",
       "       [0.98215607, 0.01784393],\n",
       "       [0.95514332, 0.04485668],\n",
       "       [0.42831772, 0.57168228]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor (KNN)\n",
    "    - https://ds.codeup.com/classification/knn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Continue working in your model file with the titanic dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_cu\n",
    "import acquire_cu\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare_cu.prep_titanic(acquire.get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['pclass', 'age', 'alone', 'fare']\n",
    "y_col = 'survived'\n",
    "\n",
    "X_train, y_train = train[x_cols], train[y_col]\n",
    "X_validate, y_validate = validate[x_cols], validate[y_col]\n",
    "X_test, y_test = test[x_cols], test[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_metrics(model):\n",
    "    '''\n",
    "    Returns a dictionary of classification metrics on the validate split given a fitted model.\n",
    "    \n",
    "    Relies on X_validate and y_validate being globally defined.\n",
    "    '''\n",
    "    predictions = model.predict(X_validate)\n",
    "    return {\n",
    "        'tpr/recall': recall_score(y_validate, predictions),\n",
    "        'tnr/specificity': recall_score(y_validate, predictions, pos_label=0),\n",
    "        'fpr': 1 - recall_score(y_validate, predictions, pos_label=0),\n",
    "        'fnr': 1 - recall_score(y_validate, predictions),\n",
    "        'f1': f1_score(y_validate, predictions),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tpr/recall': 0.5853658536585366,\n",
       " 'tnr/specificity': 0.75,\n",
       " 'fpr': 0.25,\n",
       " 'fnr': 0.41463414634146345,\n",
       " 'f1': 0.5889570552147239}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying out 1 for a guess and check try\n",
    "knn = KNeighborsClassifier(1)\n",
    "knn.fit(X_train, y_train)\n",
    "get_classification_metrics(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tpr/recall': 0.4024390243902439,\n",
       " 'tnr/specificity': 0.8257575757575758,\n",
       " 'fpr': 0.1742424242424242,\n",
       " 'fnr': 0.5975609756097561,\n",
       " 'f1': 0.4782608695652174}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying 10 for a guess and check try\n",
    "knn = KNeighborsClassifier(10)\n",
    "knn.fit(X_train, y_train)\n",
    "get_classification_metrics(knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tpr/recall': 0.4146341463414634,\n",
       " 'tnr/specificity': 0.8863636363636364,\n",
       " 'fpr': 0.11363636363636365,\n",
       " 'fnr': 0.5853658536585367,\n",
       " 'f1': 0.5190839694656488}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying out 20 for a guess and check try\n",
    "knn = KNeighborsClassifier(20)\n",
    "knn.fit(X_train, y_train)\n",
    "get_classification_metrics(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional visualization preformance as a function of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eval_knn_model(k):\n",
    "    '''\n",
    "    For a given k, fits a k-neighbors classifier with the given k value and\n",
    "    returns metrics about the model's performance.\n",
    "    \n",
    "    Returns a dictionary of k, training accuracy, and validate accuracy.\n",
    "    \n",
    "    Relies on X_train, y_train, X_validate, and y_validate being globally defined.\n",
    "    '''\n",
    "    knn = KNeighborsClassifier(k).fit(X_train, y_train)\n",
    "    return {\n",
    "        'k': k,\n",
    "        'train_score': knn.score(X_train, y_train),\n",
    "        'validate_score': knn.score(X_validate, y_validate),\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame([eval_knn_model(k) for k in range(1, 20)])\n",
    "results.set_index('k').plot(figsize=(16, 9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(range(21))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Exercises\n",
    "- https://ds.codeup.com/classification/logistic-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from acquire_cu import get_titanic_data\n",
    "from prepare_cu import titanic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Stage\n",
    "df = get_titanic_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  is_female  \\\n",
       "0         0       3  22.0      1      0   7.2500      0      False   \n",
       "1         1       1  38.0      1      0  71.2833      0       True   \n",
       "2         1       3  26.0      0      0   7.9250      1       True   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  \n",
       "0                       0                        1  \n",
       "1                       0                        0  \n",
       "2                       0                        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing ages\n",
    "avg_age = df.age.mean()\n",
    "df.age = df.age.fillna(avg_age)\n",
    "\n",
    "# Encode the gender column\n",
    "df[\"is_female\"] = (df.sex == \"female\")\n",
    "\n",
    "# Encode the embarked_town\n",
    "# Embark_Town values are Southampton, Cherbourg, and Queenstown\n",
    "dummy_df = pd.get_dummies(df[['embark_town']], dummy_na=False, drop_first=True)\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\"passenger_id\", \"deck\", \"class\", \"embarked\", \"sex\", \"embark_town\"])\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "is_female                  0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check to make sure we don't have any nulls\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datasets\n",
    "train, validate, test = titanic_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out our X and y values\n",
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline setup\n",
    "#most frequently observed outcome will beour baseline, which is 0, not surived at 307\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.616"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy = (train.survived == 0).mean()\n",
    "round(baseline_accuracy, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\n",
    "- Create a model that includes age in addition to fare and pclass.\n",
    "- Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "#create the logistic regression\n",
    "logit = LogisticRegression(random_state=123)\n",
    "\n",
    "#specify the features we are using\n",
    "features = ['age', 'pclass', 'fare']\n",
    "\n",
    "#fit a model usuing only these specified features: \n",
    "#could also use: \n",
    "#logit.fit(X_train[['age', 'pclass', 'fare']])\n",
    "logit.fit(X_train[features], y_train)\n",
    "\n",
    "#since we .fit on a subset, we will also predict on that same subset of features\n",
    "y_pred = logit.predict(X_train[features])\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. \n",
    "- Include sex in your model as well.\n",
    "    - Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, fare, and gender features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "#create the logistic regression\n",
    "logit1 = LogisticRegression(random_state=123)\n",
    "\n",
    "#specifiy the features were are using\n",
    "features = ['age', 'pclass', 'fare', 'is_female']\n",
    "\n",
    "#fit a model using only these specified features\n",
    "logit1.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit1.predict(X_train[features])\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, fare, and gender features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit1.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. \n",
    "- Try out other combinations of features and models.\n",
    " \n",
    " - Models Created:\n",
    "    - logit2, all Features, 0.82 accuracy\n",
    "    - logit3, all features with class_weight=\"balanced\", .80 accuracy\n",
    "    - logit4, only age, .62 accuracy\n",
    "    - logit5, only pclass, .67 accuracy\n",
    "    - logit6, C hyperparameter close to zero, .62 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained on all features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "# All features, all default hyperparameters\n",
    "logit2 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit2.predict(X_train)\n",
    "\n",
    "print(\"Model trained on all features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.8\n"
     ]
    }
   ],
   "source": [
    "# All features, but we'll use the class_weights to hold the actual ratios`\n",
    "logit3 = LogisticRegression(random_state=123, class_weight='balanced')\n",
    "\n",
    "logit3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit3.predict(X_train)\n",
    "\n",
    "accuracy = logit3.score(X_train, y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Only Age \n",
    "features = [\"age\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Only pclass\n",
    "features = [\"pclass\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit5 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit5.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit5.predict(X_train[features])\n",
    "accuracy = logit5.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features, C hyperparameter approaching 0\n",
      "Baseline is 0.62\n",
      "Accuracy of this Logistic Regression on training set: 0.62\n"
     ]
    }
   ],
   "source": [
    "# All Features, C=0\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit6 = LogisticRegression(random_state=123, C=0.00000000000000000001)\n",
    "\n",
    "logit6.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit6.predict(X_train)\n",
    "accuracy = logit6.score(X_train, y_train)\n",
    "\n",
    "print(\"All Features, C hyperparameter approaching 0\")\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(f'Accuracy of this Logistic Regression on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. \n",
    "- Use you best 3 models to predict and evaluate on your validate sample.\n",
    "    - logit1 trained with features = [\"age\", \"pclass\", \"fare\", \"is_female\"] has .81 accuracy\n",
    "    - logit2 trained on all features, with all other hyperparameters defaulted, has .82 accuracy\n",
    "    - logit3 trained on all features with class_weight='balanced' has accuracy of .80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit1 model using age, pclass, fare, and is_female as the features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       132\n",
      "           1       0.72      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.76      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's determine logit1's metrics on validate\n",
    "features = [\"age\", \"pclass\", \"fare\", \"is_female\"]\n",
    "\n",
    "y_pred = logit1.predict(X_validate[features])\n",
    "\n",
    "print('Logit1 model using age, pclass, fare, and is_female as the features')\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit2 model using all features and all model defaults\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.82       132\n",
      "           1       0.74      0.65      0.69        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.75      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit2 uses all features\n",
    "y_pred = logit2.predict(X_validate)\n",
    "\n",
    "print(\"Logit2 model using all features and all model defaults\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit3 model using all features, class_weight='balanced', and all other hyperparameters as default\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       132\n",
      "           1       0.70      0.72      0.71        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.77      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit3 uses all features and class_weight='balanced'\n",
    "y_pred = logit3.predict(X_validate)\n",
    "\n",
    "print(\"Logit3 model using all features, class_weight='balanced', and all other hyperparameters as default\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
